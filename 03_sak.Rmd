---
title: "R Notebook"
output: html_notebook
---

# sak



## convert continuous variables to categoricals

```{r}
data_sak_raw$class |> quantile()
data_sak_raw$weight |> quantile() #  16.40  49.30  98.00 131.25 351.00 
data_sak_raw$width |> quantile() # 4.800 13.575 16.100 20.950 64.600 
data_sak_raw$width |> hist()
data_sak_raw$Functions |> quantile() # 1 7 11 17 81
data_sak_raw$Functions |> hist() 
data_sak_raw |> 
  ggplot(aes(width, Functions, label = short_name)) +
  geom_text(size = 1.5) +
  geom_vline(xintercept = c(4.8, 13.575, 16.1, 20.95, 64.6)) +
  geom_hline(yintercept = c(7, 11, 17, 81)) +
  scale_x_continuous(trans = "log10") +
  scale_y_continuous(trans = "log10") 
data_sak_raw |> 
  ggplot(aes(width, weight, label = short_name)) +
  geom_text(size = 1.5) +
  geom_vline(xintercept = c(4.8, 13.575, 16.1, 20.95, 64.6)) +
  geom_hline(yintercept = c(15, 50, 100, 130)) +
  scale_x_continuous(trans = "log10") +
  scale_y_continuous(trans = "log10") 
```


```{r}
df_sak_longer <- data_sak_raw |> 
  filter(short_name != "OUT.Buck") |>
  mutate(
    layer_category = case_when(
      Layers == 1 ~ "Layer1",
      Layers == 2 ~ "Layers2",
      Layers == 3 ~ "Layers3",
      Layers == 4 ~ "Layers4",
      Layers > 4 ~ "LayersMoreThan4"
    ),
    # class_category = case_when(
    #   class < 84 ~ "class_Small", # 58
    #   class < 93 ~ "class_Middle", # 84, 91,
    #   class < 111 ~ "class_Large", # 100,93
    #   class >= 111 ~ "class_XL" # 111, 124 (Buck)
    # ),
    # weight_category = case_when( # 16.40  49.30  98.00 131.25 351.00
    #   weight < 50 ~ "weight_Small",
    #   weight < 100 ~ "weight_Middle",
    #   weight < 130 ~ "weight_Large",
    #   weight < 300 ~ "weight_XL",
    #   weight >= 300 ~ "weight_XXL",
    # ),
    # width_category = case_when( # 4.800 13.575 16.100 20.950 64.600
    #   width < 12 ~ "width_Small",
    #   width < 20 ~ "width_Middle",
    #   width < 30 ~ "width_Large",
    #   width < 50 ~ "width_XL",
    #   width >= 50 ~ "width_XXL",
    # ),
    # func_category = case_when( # 1 7 11 17 81
    #   Functions < 5 ~ "func_Small", 
    #   Functions < 10 ~ "func_Middle", 
    #   Functions < 15 ~ "func_Large", 
    #   Functions < 20 ~ "func_XL",
    #   Functions <= 81 ~ "func_XXL",
    # ),
    value_layer = 1L,
    # value_class = 1L,
    # value_weight = 1L,
    # value_width = 1L,
    # value_func = 1L
  ) 
# df_sak_longer |>
#   ggplot(aes(func_category)) +
#   geom_bar()
```


```{r}
df_sak_wider <- df_sak_longer |> 
  pivot_wider(names_from = layer_category, values_from = value_layer, values_fill = 0L) |>  
  # pivot_wider(names_from = class_category, values_from = value_class, values_fill = 0L) |> 
  # pivot_wider(names_from = weight_category, values_from = value_weight, values_fill = 0L) |> 
  # pivot_wider(names_from = width_category, values_from = value_width, values_fill = 0L) |> 
  # pivot_wider(names_from = func_category, values_from = value_func, values_fill = 0L) |> 
  relocate(starts_with("Layer"), .before = isLockable) |> 
  relocate("Layer1", .after = "Layers")
# View(df_sak_wider)
```

# data (without continuous-categorical variables, not used)


```{r}
df_sak <- data_sak_raw |>  
  select(-sak)　 |> 
  rowid_to_column(var = "node") |> 
  mutate(node = node |> as.integer())
```

# data

```{r}
df_sak <- df_sak_wider |> 
  select(-sak) |> 
  rowid_to_column(var = "node") |> 
  mutate(node = node |> as.integer())
```

## data summary

```{r}
df_sak |> group_by(class) |> 
  summarize(n = n())
```

## corresp

data <https://www1.doshisha.ac.jp/~mjin/R/Chap_26/26.html> use FactoMineR instead of MASS to get eigen values

```{r fig.width=5, figh.height = 3}

df_sak_factor <- df_sak |> 
  select(Layer1:MetalG) |> 
  mutate(across(everything(), as.factor))
sak_mca <- MCA(df_sak_factor, ncp = 2, graph = FALSE)

df_sak_mca_coord <- sak_mca$ind$coord |> 
  as_tibble() |> 
  transmute(mca_x = `Dim 1`, mca_y = `Dim 2`)


# http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/114-mca-multiple-correspondence-analysis-in-r-essentials/
# extract eigen value
sak_corresp_eigen_values <- get_eigenvalue(sak_mca)
# check eigen v
fviz_screeplot(sak_mca, addlabels = TRUE, ylim = c(0, 20))

# variance explained by dim1 and dim2 are:
# they are later used in the ggplot
sak_corresp_dim1_ev <- sak_corresp_eigen_values[1, 2]
sak_corresp_dim2_ev <- sak_corresp_eigen_values[2, 2]

# coordinates
df_sak_factor2 <- bind_cols(df_sak, df_sak_mca_coord)

```

#### plot all corresp

```{r}
df_sak_factor2 |>
  ggplot(aes(-mca_x, mca_y, label = short_name, colour = Functions)) +
  # geom_point(data = df_sak_factor2 |> select(-class), colour = "grey70") +
  geom_text(aes(label = class),
            family = "Alte DIN 1451 Mittelschrift",
            fontface = "bold"
            ) +
  geom_text_repel(
    # force = .3,
    force_pull = 2,
    max.overlaps = 30, 
    max.time = 3, 
    max.iter = 3e5, 
    size = 1.5,
    min.segment.length = .1, 
    family = "Fira Code",
    segment.colour = NA
    
    ) +
  scale_colour_viridis_c(trans = "log10", limits = c(1, 35)) +
  scale_size_area() +
  # labs(colour = "Price (1k yen)" ) +
  xlab(paste0("Dimension 1 (", sak_corresp_dim1_ev |> round(digits = 1), "%)")) +
  ylab(paste0("Dimension 2 (", sak_corresp_dim2_ev |> round(digits = 1), "%)")) +
  theme_bw(base_family = "Fira Code") +
  theme(panel.background = element_rect(fill = "white", colour = "black")) +
  guides(colour = guide_colourbar(barwidth = 5, barheight = .5), direction = "horizontal") +
  theme(legend.direction = "horizontal", legend.position = c(0.2, 0.1),
        panel.grid = element_blank())
```

### if fine, save
```{r}
ggsave(filename = "output/sak_correspXY_all.pdf", 
         device = cairo_pdf,
         dpi = 300,
         unit = "mm",
       height = 100, 
       width = 166, 
       limitsize = FALSE)
```

cut the trees

<https://uc-r.github.io/hc_clustering>

```{r}
df_fviz_wss <- df_sak_factor |> 
  fviz_nbclust(FUN = hcut, method = "wss", k.max = 30)

df_fviz_wss2 <- df_fviz_wss$data |> 
  mutate(clusters = as.numeric(clusters))
plot_sak_elbow <- df_fviz_wss2 |>   
  ggplot(aes(clusters, y)) +
  geom_line() +
  # geom_point() +
  ylab("Total WSS") +
  xlab("No of clusters k") +
  theme_classic(base_family = "Fira Code")

# silhouette
fviz_sil <- df_sak_factor |> 
  fviz_nbclust(FUN = hcut, method = "silhouette", k.max = 30)
df_fviz_sil <- fviz_sil$data |> 
  mutate(clusters = as.numeric(clusters))
# check optimal cluster size
fviz_sil
```


```{r}
plot_sak_sil <- df_fviz_sil |>   
  ggplot(aes(clusters, y)) +
  geom_line() +
  geom_vline(xintercept = 17, linetype = "dashed", colour = "gray90") +
  ylab("Avg sil width") +
  xlab("No of clusters k") +
  theme_classic(base_family = "Fira Code")
# cowplot
plot_grid(plot_sak_elbow, plot_sak_sil, 
          align = "hv",
          ncol=2, 
          labels=LETTERS)
ggsave(filename = "output/sak_sil_elbow.pdf", 
       device = cairo_pdf,
       dpi = 200,
       unit = "mm",
       height = 60, # pixelsでのサイズ
       width = 150,  # pixelsでのサイズ
       limitsize = FALSE)

```



# distance: hamming

SplitsTree4のUncorrectedPがHamming距離である。{e1071}の`hamming.distance()`をつかう。`hammingdists()`はダメ

```{r}
sak_dist <- hamming.distance(df_sak_factor |> as.matrix()) |> as.dist()
# sak_dist |> nj() |> plot() # do not plot distance directly using nj()! it breaks everything, idk why
```

# construct trees

## construct a UPGMA tree

```{r}
sak_upgma <- sak_dist |>
  hclust(method = "average") |> # average = UPGMA
   as.phylo()
sak_upgma$tip.label <- df_sak$short_name

# sak_upgma |> 
  # plot.phylo(type = "u", use.edge.length = TRUE, lab4ut = "axial")
```

## NJ

```{r}
sak_nj <- sak_dist |> nj()
sak_nj$tip.label <- df_sak$short_name
sak_nj |> 
  ggtree(layout = "ape") +
  geom_tiplab(size = 2, hjust = -.1)
```

## join traits

### UPGMA

```{r}
df_sak_upgma <- sak_upgma |>
  as_tibble() |> 
  left_join(df_sak, by = "node") |> 
  select(parent:class, short_name, Functions, width, weight) |> 
  mutate(short_name = if_else(is.na(short_name), node |> as.character(), short_name)) |> 
  column_to_rownames(var = "short_name") |> 
  mutate(node = node |> as.numeric()) |> 
  select(node, class, Functions, weight, width) # temporarily limite
```

### NJ

```{r}
df_sak_nj <- sak_nj |> 
  as_tibble() |> 
  left_join(df_sak, by = "node") |> 
  select(parent:class, short_name, Functions, width, weight) |> 
  mutate(short_name = if_else(is.na(short_name), node |> as.character(), short_name)) |> 
  column_to_rownames(var = "short_name") |> 
  mutate(node = node |> as.numeric()) |> 
  select(node, class, Functions, weight, width)
```


## join tree with df for plot

```{r}
# join with tree. seems impossible but possible :D
sak_upgma2 <- full_join(sak_upgma, df_sak_upgma, by = "node")
sak_nj2 <- full_join(sak_nj, df_sak_nj, by = "node")
```

```{r}
sak_upgma2 |> 
  ggtree(layout = "ape", aes(colour = class)) +
  geom_tiplab(aes(label = paste0(class, label)), size = 2, hjust = -0.2) +
  scale_colour_viridis_c()
sak_nj2 |> 
  ggtree(layout = "ape", aes(colour = class)) +
  geom_tiplab(aes(label = paste0(class, label)), size = 2, hjust = -0.2) +
  scale_colour_viridis_c()
```
# output

```{r fig.width = 5, fig.height=5}
getwd()
df_sak_factor |> 
  mutate(name = paste0(df_sak$class, df_sak$short_name)) |>
  relocate(name) |>
  # column_to_rownames("name") |> 
  write_tsv("data/sak_factor2_for_mesquite_nex.tsv")

# sak_nj |> write.nexus("data/sak_factor.nex") does not work
```
TSVをMesquiteで開く→TSV(Categorical)を選んで、1行目はキャラクターの名前？みたいなのにYesしてNEXで保存
NEXをVSCodeで開き、TITLEを消し、数字のあとのEND;以降の、Mesquite関連と思われる部分を消す
→SplitsTree4で開けるようになるので、開く
デフォルトでHammingになっているので、そのままFilterで0.003に設定した（これの正しい値は特になさそう）。
BS値（デフォルトの1000で十分らしい）やDeltaを計算し、タクサの位置を適当にいじって、PDFで書き出す
PDFはそのままだとIllustratorで開けないので、Previewで開き、別名で保存でPDF/Aにするにチェックを入れると開けるようになる




# parsimony

## parsimony score

p-score

> The parsimony score for each tree is the sum of the smallest number of substitutions needed for each site. The
tree with the lowest parsimony score is the most parsimonious tree. There are often ties. - [source](http://pages.stat.wisc.edu/~larget/Genetics629/Fall2009/outline2.pdf)

create phyDat data for mparsimony tree and categorical phenotype reconstruction

```{r}
df_sak_phyDat <- df_sak_factor |> 
  mutate(name = df_sak$short_name) |> 
  relocate(name) |> 
  rownames_to_column() |> 
  pivot_longer(-name, 'variable', 'value') |> 
  pivot_wider(variable, name) |> 
  filter(variable != "rowname") |> 
  mutate(across(everything(), as.character)) |> 
  column_to_rownames(var = "variable")
sak_phyDat <-df_sak_phyDat |> 
  phyDat(type = "USER", levels = c("0", "1")) 
```

### compare 
```{r}
sak_nj |> 
  parsimony(sak_phyDat) # 252
sak_upgma |> 
  parsimony(sak_phyDat) # 285. worse

```
[phangorn](https://rdrr.io/cran/phangorn/man/parsimony.html)を用いて最節約法をする。pratchet()を最終的には使う。

```{r fig.width = 5, fig.height = 5}
# "optim.parsimony tries to find the maximum parsimony tree using either Nearest Neighbor Interchange (NNI) rearrangements or sub tree pruning and regrafting (SPR)"
sak_parsimony_nj <- optim.parsimony(sak_nj, sak_phyDat) # start with a nj tree, Final p-score 236 after  5 nni operations 
sak_parsimony_upgma <- optim.parsimony(tree = sak_upgma, data = sak_phyDat) # start with a upgma tree, Final p-score 235 after  16 nni operations (better...?)

sak_parsimony_nj |> plot(type = "unrooted") # cladogram with no branch length

# "pratchet implements the parsimony ratchet (Nixon, 1999) and is the preferred way to search for the best tree"
sak_parsimony <- pratchet(sak_phyDat, trace = 0, minit = 100) # 20 sec
parsimony(c(sak_parsimony_nj, sak_parsimony_upgma, sak_parsimony), data = sak_phyDat) # 236, 235, 234 so pratchet() barely the best
# give them branch length
sak_parsimony <- sak_parsimony |> 
  acctran(sak_phyDat)
sak_parsimony |> 
  ggtree(layout = "ape") +
  geom_tiplab(size = 2, hjust = -.2) +
  geom_nodelab(color = "lightblue", size = 1.5)
```
### NJ Bootstrapping with phyDat / phangorn

なんかもうひとつのboot.phylo()がうまくいってるのかわからないのでこちらを使う。NJ / UPGMAの場合、bootstrap.phyDat()を使う[source document](https://rdrr.io/cran/phangorn/man/bootstrap.pml.html)
```{r}
set.seed(913)
# nj
sak_nj_bs_trees <- sak_phyDat |> 
  bootstrap.phyDat(
    FUN = \(x) {
      x |> dist.hamming() |> NJ()
    },
    bs = 1000) # 2sec

sak_nj_bs <- plotBS(sak_nj, sak_nj_bs_trees)
sak_nj_bs |> ggtree() +
  geom_nodelab()
# upgma
sak_upgma_bs_trees <- sak_phyDat |> 
  bootstrap.phyDat(
    FUN = \(x) {
      x |> dist.hamming() |> 
        hclust(method = "average") |> 
        as.phylo()
    },
    bs = 1000
  ) # 3sec
sak_upgma_bs <- plotBS(sak_upgma, sak_upgma_bs_trees)
sak_upgma_bs |> ggtree() +
  geom_nodelab(vjust = -.5, hjust = 1, nudge_x = -.2, size = 2)
```
## join traits for parsimony

```{r}
df_sak_parsimony <- sak_parsimony |> 
  as_tibble() |> 
  left_join(df_sak, by = "node") |> 
  select(parent:class, short_name, Functions, width, weight) |> 
  mutate(short_name = if_else(is.na(short_name), node |> as.character(), short_name)) |> 
  column_to_rownames(var = "short_name") |> 
  mutate(node = node |> as.numeric()) |> 
  select(node, class, Functions, weight, width)
```



# what next?
plot (04) or ancestral character reconstruction(02).

# appendices

参考。phyDatでカテゴリカルなものを復元しようとしたり
### neighbornet

できるけど…
SplitsTree4のものを読み込めるらしいので、それでやってみるか

plot isn't really good and does not match exactly with SplitsTree4 output, probably because `neighborNet()` func is experimental. use SplitsTree4 using write.nexus()?

```{r fig.width = 5, fig.height=5}
sak_dist2 <- sak_phyDat |> dist.hamming() # must be phyDat
sak_nn_test <- sak_dist2 |>
  neighborNet() # takes 30sec

sak_nn_test |> as_tibble()
sak_nn_test |> write.nexus.networx(file = "data/sak_network_networx.nex")
# read and save again on st4
sak_nn_test2 <- read.nexus.networx(file = "data/sak_network_networx.nex")
sak_nn_test2 |> as_tibble() |> View() # duplicate branches? no, except for one (node 1)
sak_nn_test2 |> ggsplitnet() # can be rendered
sak_nn <- read.nexus.networx(file = "data/sak_networkFilter003_bs.nex")
sak_nn |> as_tibble() |> View() #61 tips, 237 internal nodes
sak_nn_test2 # 62 tips, 907 internal nodes

sak_nn2 <- sak_nn |> 
  as_tibble() |> 
  filter(branch.length > 0) |> 
  as.phylo()
sak_nn2 |> View()
sak_nn2 |> 
  ggsplitnet()
sak_nn2 |> 
  ggsplitnet(ladderize = FALSE)
sak_nn_test |> 
  ggsplitnet()
df_sak_nn <- sak_nn |> 
  as_tibble() |> #View()
  left_join(df_sak_rowid, by = "node") |>
  select(parent:class, short_name, Functions, width, weight, id) |> 
  rowid_to_column() |> 
  mutate(short_name = if_else(is.na(short_name), rowid |> as.character(), short_name)) |>
  # column_to_rownames(var = "short_name") |>
  mutate(node = node |> as.numeric()) |>
  select(short_name, node, class, id, Functions, weight, width)
sak_nn2 <- full_join(sak_nn, df_sak_nn, by = "node")
```

### plot NN

```{r}
sak_nn |>  ggsplitnet() 
  geom_splitnet(size = .1) +
  geom_tiplab2(size = 2, family = "Fira Code", hjust = -.1) +
  theme_tree() +
  ggexpand(.1) + 
  ggexpand(.1, direction=-1)
ggsave(filename = "output/sak_nn.pdf", 
       device = cairo_pdf,
       dpi = 450,
       unit = "mm",
       height = 360, # pixelsでのサイズ
       width = 360,  # pixelsでのサイズ
       limitsize = FALSE)
```

networx()ではかなりできることが少ないので、SplitsTree4を使わないといけなさそう：



```{r}
# data(yeast, package="phangorn")
# dm <- phangorn::dist.ml(yeast)
# nnet <- phangorn::neighborNet(dm)

```

## Delta Score

{phangorn} provides `delta.score()`. [document](https://rdrr.io/cran/phangorn/man/delta.score.html) ##\# example

デルタスコア計算できるのはいいけど、ネットワークの形がSplitsTree4と違うので参考程度にしかならないか。

```{r}
data(yeast)
hist(delta.score(yeast, "all"))
```

```{r}
# compute delta score. takes 1min, sometimes it fails with error object 'decreasing' not found
# re-run it and it works (at least it worked)
sak_delta_all <- sak_phyDat |> delta.score(arg = "all") 


sak_delta_all |> 
  hist()
mean(sak_delta_all) # identical to delta.score()
length(sak_delta_all)


```




